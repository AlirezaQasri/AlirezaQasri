# -*- coding: utf-8 -*-
"""Untitled31.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Nsjg0RYcmFaBNBWJV7cWPUD6sjUqqLb9
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

import numpy as np
import pandas as pd

train=pd.read_csv('train.csv')

train.info()

train.sample()

train['Title'] = train['Name'].str.extract('([A-Za-z]+)\.', expand=False)

train['Title']

sex = pd.get_dummies(train['Sex'],drop_first=True)

sex

embark=pd.get_dummies(train['Embarked'])

train = pd.concat([train,sex,embark],axis=1)

train.sample(10)

train.drop(['Name','Sex','PassengerId'],axis=1,inplace=True)

train['Tiklet']=train['Ticket'].str.extract('([a-zA-Z]+)', expand=False)

train['Tiklet'].value_counts()

train.drop(['Ticket'],axis=1, inplace=True)

train['Familysize']=train['SibSp']+train['Parch']

train

train.drop(['SibSp','Parch'],axis=1, inplace=True)

train['Cablet']=train['Cabin'].str.extract('([a-zA-Z]+)', expand=False)

train.drop('Cabin',axis=1, inplace=True)

train

embarked_mapping = {"S": 0, "C": 1, "Q": 2}
train['Embarked'] = train['Embarked'].map(embarked_mapping)

train

mappingshit={
    'Mr':0,  
'Miss':  0.75 ,
'Mrs':    1.5   ,
'Master':   2.25 ,
'Col':       3 ,
'Rev' :       3,
'Ms'   :       3,
'Dr'    :      3,
'Dona':3
}
train['Title']=train['Title'].map(mappingshit)

train

title_mapping ={'PC':0 , 
'C':0.3,
'A':0.6,
'STON':0.9,
'SOTON':1.2,    
'S': 1.5    ,   
'CA': 1.8   ,  
'SC': 2.1     , 
'W':  2.4     ,
'F':   2.7      ,
'LINE':3    ,
'PP':       3 ,
'P':       3  ,
'WE':     3  ,
'SO':    3   ,
'Fa':   3   ,
'SW':  3   ,
'SCO':3
    
}
train['Tiklet'] = train['Tiklet'].map(title_mapping)

train["Fare"].fillna(train.groupby("Pclass")["Fare"].transform("median"), inplace=True)

test=train.drop('Survived', axis=1)

train_test_data = [train]

type(train_test_data)

type(train)

for dataset in train_test_data:
    dataset.loc[dataset['Fare'] <= 17, 'Fare'] = 0
    dataset.loc[(dataset['Fare'] > 17) & (dataset['Fare'] <= 30), 'Fare'] = 1
    dataset.loc[(dataset['Fare'] > 30) & (dataset['Fare'] <= 100), 'Fare'] = 2
    dataset.loc[ dataset['Fare'] > 100, 'Fare'] = 3

train['Fare'].value_counts()



train['Cablet'].value_counts()

cabletmap={
'C' :0,    
'B' :0.6 ,  
'D' : 1.2 ,
'E': 1.8,
'A' :2.4,
'F':  3,
'G': 3 ,
'T' :3
}
train['Cablet']=train['Cablet'].map(cabletmap)

train.info()

plt.figure(figsize=(12, 7))
sns.boxplot(x='Pclass',y='Age',data=train,palette='winter')





train.info()

np.sum(np.isnan(train))

test= train.drop('Survived',axis=1 )

for dataset in train_test_data:
  
    dataset.loc[ dataset['Age'] <= 11, 'Age'] = 0
    dataset.loc[(dataset['Age'] > 11) & (dataset['Age'] <= 18), 'Age'] = 1
    dataset.loc[(dataset['Age'] > 18) & (dataset['Age'] <= 22), 'Age'] = 2
    dataset.loc[(dataset['Age'] > 22) & (dataset['Age'] <= 27), 'Age'] = 3
    dataset.loc[(dataset['Age'] > 27) & (dataset['Age'] <= 33), 'Age'] = 4
    dataset.loc[(dataset['Age'] > 33) & (dataset['Age'] <= 40), 'Age'] = 5
    dataset.loc[(dataset['Age'] > 40) & (dataset['Age'] <= 66), 'Age'] = 6
    dataset.loc[ dataset['Age'] > 66, 'Age'] = 6

train['Age']

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(train.drop('Survived',axis=1), 
                                                    train['Survived'], test_size=0.30, 
                                                    random_state=101)

from sklearn.pipeline import make_pipeline

from sklearn.impute import SimpleImputer

from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC

import numpy as np

model= make_pipeline(
    SimpleImputer(strategy='constant',fill_value=0),
     GaussianNB()
)
model.fit(X_train,y_train)

predictions = model.predict(X_test)

from sklearn.metrics import confusion_matrix
accuracy=confusion_matrix(y_test,predictions)

from sklearn.metrics import accuracy_score
accuracy=accuracy_score(y_test,predictions)
accuracy

from sklearn.metrics import classification_report
print(classification_report(y_test,predictions))

model= make_pipeline(
    SimpleImputer(strategy='constant',fill_value=0),
    SVC()
)
model.fit(X_train,y_train)

predictions = model.predict(X_test)

from sklearn.metrics import accuracy_score
accuracy=accuracy_score(y_test,predictions)
accuracy

from sklearn.metrics import classification_report
print(classification_report(y_test,predictions))

model= make_pipeline(
    SimpleImputer(strategy='constant',fill_value=0),
    DecisionTreeClassifier()
)
model.fit(X_train,y_train)

predictions = model.predict(X_test)

from sklearn.metrics import classification_report
print(classification_report(y_test,predictions))

from sklearn.metrics import accuracy_score
accuracy=accuracy_score(y_test,predictions)
accuracy

from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
k_fold = KFold(n_splits=10, shuffle=True, random_state=0)

train.replace([np.inf, -np.inf], np.nan, inplace=True)

train.fillna(train.mean())

train_data = train.drop('Survived', axis=1)
target = train['Survived']

train=train.fillna(train.mean())

np.sum(np.isnan(train))

clf = DecisionTreeClassifier()
scoring = 'accuracy'
score = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)
print(score)

round(np.mean(score)*100, 2)

